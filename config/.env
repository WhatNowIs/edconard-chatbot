# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=
# The provider for the AI models to use.
MODEL_PROVIDER='openai'

# The name of LLM model to use.
MODEL='gpt-4o'
# MODEL='gpt-4o-mini'

# Name of the embedding model to use.
EMBEDDING_MODEL='text-embedding-3-small'

# Dimension of the embedding model to use.
EMBEDDING_DIM='1536'

# The OpenAI API key to use.
# OPENAI_API_KEY=

# The address to start the backend app.
APP_HOST=0.0.0.0

# The port to start the backend app.
APP_PORT=8000

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

VECTOR_STORE_PROVIDER=chroma

# The directory to store the llamaindex's storage files.
STORAGE_DIR="storage/context"

# The name of the collection in your Chroma database
CHROMA_COLLECTION=default

# The API endpoint for your Chroma database
# CHROMA_HOST=

# The port for your Chroma database
# CHROMA_PORT=

# The local path to the Chroma database. 
# Specify this if you are using a local Chroma database. 
# Otherwise, use CHROMA_HOST and CHROMA_PORT config above
CHROMA_PATH="storage/chromadb"
# DB_URI=DB_URI=postgresql://postgres:password@localhost:5432/database-name
# Custom system prompt.
# Example:
SYSTEM_PROMPT='You are a helpful assistant who helps users with their questions. Always provide necessary references for response you provide.'
# SYSTEM_PROMPT=
# OPENAI_API_KEY=
OPENAI_API_VERSION='2024-02-01'
FROM_EMAIL='patrick@whatnow.is'
# Local database connect
# #OpenTelemetry Collector
# OTLP_ENDPOINT = http://localhost:4317
# #Postgres
# #Rate limit
REDIS_URL='redis://localhost'
# RATE_LIMITER_TIMES = 50
# RATE_LIMITER_DURATION = 60
# AWS_KEY = 
# AWS_SECRET = 
# S3_REGION = 
# S3_BUCKET_NAME = 
# S3_ASSET_BUCKET_NAME = 
# GCP_SCOPES = 
# TOPICS_SPREADSHEET_URL=
# SHEETS_NAMES =
# RESEND_API_KEY='re_KQqZTneP_HociczHNM1fWmYDXLzi456Lr'
